## 1. 正则表达式 

- **优点**：
  - **速度快**：几乎无延迟，完全满足项目“延迟低于400毫秒”的要求。
  - **零成本**：无需训练数据，只需人工定义规则，适合项目冷启动阶段。
- **缺点**：
  - **泛化能力差**：无法处理用户的新说法、同义句或口语化表达，只能识别规则内包含的模式。
  - **维护成本高**：随着意图数量增加（项目要求20+个），规则会变得极其复杂且难以维护，容易产生冲突。

## 2. TFIDF 

- **优点**：
  - **速度快**：基于统计特征，计算量小，容易满足400ms的延迟要求，适合部署在算力有限的车载边缘设备上。
  - **实现简单**：技术成熟，代码结构简单，依赖较少（仅需`sklearn`, `jieba`等）。
- **缺点**：
  - **缺乏语义理解**：基于词袋模型（Bag of Words），忽略了词序和上下文信息，难以区分“我给李四打电话”和“李四给我打电话”。

## 3. BERT

- **优点**：
  - **高准确率**：具备强大的上下文语义理解能力，能够很好地处理同义词、多义词和复杂句式。
  - **泛化能力强**：通过在大规模语料上预训练，对未见过的表达方式有较好的推断能力。
- **缺点**：
  - **推理延迟高**：模型参数量大，推理计算复杂。
  - **资源消耗大**：需要 GPU 进行训练，部署时对硬件算力（显存/内存）有较高要求。
  - **训练成本高**：需要较长的训练时间和更多的高质量标注数据。

## 4. LLM 

- **优点**：
  - **泛化能力强**：能极好地处理长尾意图和极其复杂的口语表达。
  - **灵活性**：对于新增的意图类别，只需在数据库/参考例子中添加即可，无需重新训练模型。
- **缺点**：
  - **延迟与成本风险最大**：API 调用通常耗时较长（可能超过400ms），且产生 token 费用，不适合高频调用。
  - **不可控性**：虽然 Prompt 限制了输出格式，但大模型仍可能生成非预期内容，存在稳定性风险。
